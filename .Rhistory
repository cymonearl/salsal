cor.test(quakes$lat, quakes$long)
ggplot(mtcars, aes(x = mpg, y = hp)) +
geom_point() +
geom_smooth(method = lm, se = FALSE) +
labs(title = "Scatter Plot of HP vs MPG",
x = "Horsepower (HP)",
y = "Miles per Gallon (MPG)")
ggplot(mtcars, aes(x = hp, mpg)) +
geom_point() +
geom_smooth(method = lm, se = FALSE) +
labs(title = "Scatter Plot of HP vs MPG",
x = "Horsepower (HP)",
y = "Miles per Gallon (MPG)")
ggplot(mtcars, aes(x = hp, y = mpg)) +
geom_point() +
geom_smooth(method = lm, se = FALSE) +
labs(title = "Scatter Plot of HP vs MPG",
x = "Horsepower (HP)",
y = "Miles per Gallon (MPG)")
cor.test(mtcars$hp, mtcars$mpg)
cor.test(mtcars$mpg, mtcars$hp)
cor(., .)
cor(1, 2)
?cor()
cor(., ., mtcars)
cor(., ["hp", "mpg"], mtcars)
cor(., ["hp", "mpg"], use=mtcars)
cor(., "hp", "mpg", use=mtcars)
cor(., {"hp", "mpg"}, use=mtcars)
cor(mtcars)
cor(., c(mpg, cyl)mtcars)
cor(., c(mpg, cyl), mtcars)
cor(., c("mpg", "cyl"), mtcars)
cor(. c("mpg", "cyl"), mtcars)
data()
cor(women)
cor(Orange)
cor(orange)
cor(Orange)
cor(Nile)
cor(Titanic)
cor(AirPassengers)
cor(CO2)
cor(EuStockMarkets)
cor(EuStockMarkets[,])
cor(EuStockMarkets[, c(1,3)])
cor(EuStockMarkets[, c(1,3)], kendall)
cor(EuStockMarkets[, c(1,3)], "kendall")
cor(EuStockMarkets[, c(1,3)], method = "kendall")
cor(EuStockMarkets[, c(1,3)], method = c(.))
cor(EuStockMarkets[, c(1,3)], method = c())
cor(EuStockMarkets[, c(1,3)], method = c(1,2,3,4))
cor(EuStockMarkets[, c(1,3)], method = c(1,2,3))
cor(EuStockMarkets[, c(1,3)], method = c(1,2))
cor(EuStockMarkets[, c(1,3)], method = c(1))
cor(EuStockMarkets[, c(1,3)], method = c("spearman"))
ggplot(EuStockMarkets, aes(x=1, y=2)) +
geom_smooth(method = lm, se = FALSE)
library(tidyverse)
ggplot(EuStockMarkets, aes(x=1, y=2)) +
geom_smooth(method = lm, se = FALSE)
cor(EuStockMarkets[, c(1,3)], method = c("spearman"))
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_smooth(method = lm, se = FALSE)
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point()
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point() +
geom_smooth(method = lm, se = FALSE)
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point() +
geom_smooth(method = lm, se = TRUE)
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point() +
geom_smooth(method = lm, se = TRUE)
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point() +
geom_smooth(method = lm, se = TRUE) +
labs("EuStocksMarkets")
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point() +
geom_smooth(method = lm, se = TRUE) +
labs(title = "EuStocksMarkets",
x = "DAX",
y = "CAC")
ggplotly(ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point() +
geom_smooth(method = lm, se = TRUE) +
labs(title = "EuStocksMarkets",
x = "DAX",
y = "CAC"))
ggplot(EuStockMarkets, aes(x=DAX, y=CAC)) +
geom_point() +
geom_smooth(method = lm, se = TRUE) +
labs(title = "EuStocksMarkets",
x = "DAX",
y = "CAC")
cor(EuStockMarkets[, c(1,3)], method = c("spearman"))
cor(EuStockMarkets, method = c("spearman"))
cor(EuStockMarkets)
model <- lm(DAX ~ SMI + CAC + FTSE, EuStockMarkets)
summary(model)
model <- lm(DAX ~ SMI + CAC + FTSE, EuStockMarkets)
summary(model)
cor(EuStockMarkets)
model <- lm(DAX ~ SMI + CAC + FTSE, EuStockMarkets)
summary(model)
cor(EuStockMarkets)
model <- lm(DAX ~ SMI + CAC + FTSE, EuStockMarkets)
summary(model)
predict(model, data.frame(SMI = 100))
predict(model, data.frame(SMI = 100, CAC = 100, FTSE = 100))
model <- lm(DAX ~ SMI + CAC, EuStockMarkets)
predict(model, data.frame(SMI = 100, CAC = 100))
model <- lm(DAX ~ CAC, EuStockMarkets)
summary(model)
predict(model, data.frame(SMI = 100, CAC = 100))
library(shiny); runApp('Shiny Script.R')
library(tidyverse)
data <- read_csv("C:/Users/creep/Downloads/messy_sales_data.csv")
summary(data)
glimpse(data)
total <- data |>
filter(price, price > 100)
?filter
total <- data |>
filter(price > 100)
glimpse(data)
glimpse(total)
select <- data |>
select(transaction_id, costumer_id, total)
select <- data |>
select(transaction_id, costumer_id, total)
select <- data |>
select(transaction_id, customer_id, total)
print(select)
select
select <- data |>
distinct()
select
select <- data |>
select(transaction_id, customer_id, total)
select <- distinct()
select <- select |>
distinct()
select
new_data <- data |>
filter(select, transaction_id)
new_data <- data |>
filter(select, transaction_id == select$transaction_id)
new_data <- data |>
filter(select, data$transaction_id == select$transaction_id)
new_data <- data |>
filter(data$transaction_id == select$transaction_id)
new_data
new_data <- new_data |>
mutate(date = lubridate::ymd(date))
new_data
new_data <- new_data |>
mutate(date = lubridate::m(date))
new_data <- data |>
mutate(quantity = price / total)
new_data
new_data <- data |>
mutate(quantity = total / price)
new_data
new_data <- fill(date, .direction = "down")
new_data <- |>
new_data <- new_data |>
fill(date, .direction = "down")
new_data
new_data <- new_data |>
replace_na(region, "Unknown")
new_data
new_data <- new_data |>
replace_na(region, "Unknown" na.rm = TRUE)
new_data <- new_data |>
mutate(region = replace_na("Unknown"))
new_data
data <- read_csv("C:/Users/creep/Downloads/messy_sales_data.csv")
total <- data |>
filter(price > 100)
select <- data |>
select(transaction_id, customer_id, total)
select <- select |>
distinct()
new_data <- data |>
mutate(quantity = total / price)
new_data <- new_data |>
fill(date, .direction = "down")
new_data <- new_data |>
mutate(region = replace_na(region, "Unknown"))
new_data
new_data |>
drop_na()
new_data |>
tolower(product)
new_data |>
tolower(new_data, product)
new_data |>
mutate(
product = tolower(product)
)
new_data |>
mutate(
product = tolower(product)
)
new_data <- new_data |>
mutate(
product = tolower(product)
)
new_data <- new_data |>
drop_na()
new_data
dates <- new_data |>
select(date) |>
dates <- new_data |>
mutate(year = lubridate::year(date),
month = lubridate::month(date, label = TRUE),
day_of_week = lubridate::wday(date, label = TRUE))
dates <- new_data |>
mutate(year = lubridate::year(date),
month = lubridate::month(date, label = TRUE),
day_of_week = lubridate::wday(date, label = TRUE))
dates
data <- read_csv()
data <- read_csv(open.srcfile())
data <- read_csv(file.choose())
data <- read_csv(choose.files())
summary(data)
glimpse(data)
total <- data |>
filter(price > 100)
select <- data |>
select(transaction_id, customer_id, total)
print(select)
print(select)
select <- select |>
distinct()
print(select)
dates <- new_data |>
select(date)
print(dates)
source("~/.active-rstudio-document", echo=TRUE)
print(new_data)
dates <- new_data |>
mutate(year = lubridate::year(date),
month = lubridate::month(date, label = TRUE),
day_of_week = lubridate::wday(date, label = TRUE))
print(new_data)
write_csv(new_data, "cleaned_data.csv")
print(new_data)
print(new_data)
dates <- new_data |>
mutate(year = lubridate::year(date),
month = lubridate::month(date, label = TRUE),
day_of_week = lubridate::wday(date, label = TRUE))
print(new_data)
new_data <- new_data |>
drop_na()
print(new_data)
new_data <- new_data |>
mutate(
product = tolower(product)
)
print(new_data)
dates <- new_data |>
mutate(year = lubridate::year(date),
month = lubridate::month(date, label = TRUE),
day_of_week = lubridate::wday(date, label = TRUE))
print(new_data)
print(dates)
ggplot(new_data, aes(y = total))
boxplot()
ggplot(new_data, aes(y = total)) +
boxplot()
ggplot(new_data, aes(y = total)) +
geom_boxplot()
q1 <- quantile(new_data$total, 0.25, na.rm = TRUE)
q3 <- quantile(new_data$total, 0.75, na.rm = TRUE)
iqr <- q3 - q1
n_data <- new_data |>
filter(total >= (q1 - 1.5 * iqr) & total <= (q3 - 1.5 * iqr))
print(n_data)
q1 <- quantile(new_data$total, 0.25, na.rm = TRUE)
q3 <- quantile(new_data$total, 0.75, na.rm = TRUE)
iqr <- q3 - q1
n_data <- new_data |>
filter(total >= (q1 - 1.5 * iqr) & total <= (q3 - 1.5 * iqr))
print(n_data)
print(new_data)
q1 <- quantile(new_data$discount, 0.25, na.rm = TRUE)
q3 <- quantile(new_data$discount, 0.75, na.rm = TRUE)
iqr <- q3 - q1
n_data <- new_data |>
filter(total >= (q1 - 1.5 * iqr) & total <= (q3 - 1.5 * iqr))
print(n_data)
r_data <- new_data |>
mutate(revenue = quantity * price - discount)
print(r_data)
q_data <- new_data |>
filter(total >= (q1 - 1.5 * iqr) & total <= (q3 - 1.5 * iqr))
print(n_data)
new_data <- new_data |>
mutate(revenue = quantity * price - discount)
print(r_data)
new_data <- new_data |>dates <- new_data |>IQR()
mutate(year = lubridate::year(date),
month = lubridate::month(date, label = TRUE),
day_of_week = lubridate::wday(date, label = TRUE))
new_data <- new_data |>
mutate(year = lubridate::year(date),
month = lubridate::month(date, label = TRUE),
day_of_week = lubridate::wday(date, label = TRUE))
print(dates)
write_csv(new_data, "cleaned_data.csv")
view(new)data
view(new_data)
glimpse(new_data)
?args
formals?
as
?formals
?args
?local
?function
a''
??function
asdf
a
s
?f
?function
sa
?function()
as
?return
?=
?<-
return(final)
this <- function(one, two) {
final <- one + two
return(final)
}
this(1,2)
library(shiny); runApp('Programs/R/Penguin Shiny.R')
package("tidemodels")
package("tidymodels")
package("tidymodel")
library(shiny); runApp('Programs/R/Penguin Shiny.R')
library(shiny)
library(tidymodels)
library(tidyverse)
ui <- fluidPage(
# Application title
titlePanel("Predicting Penguin Species"),
sidebarLayout(
sidebarPanel(
sliderInput("bill_length",
"bill length (mm)",
min = 32.1,
max = 59.6,
value = 45),
sliderInput("bill_depth",
"bill depth (mm)",
min = 13.1,
max = 21.5,
value = 18),
sliderInput("flipper_length",
"flipper length (mm)",
min = 172,
max = 231,
value = 196),
sliderInput("body_mass",
"body mass (g)",
min = 2700,
max = 6300,
value = 5400),
),
mainPanel(
tableOutput("prediction"),
h1(tableOutput("value"))
)
)
)
server <- function(input, output) {
datainput <- reactive({
penguins <- data.frame(
input$bill_length,
input$bill_depth,
input$flipper_length,
input$body_mass
)
colnames(penguins) <- c(
"bill_length_mm",
"bill_depth_mm",
"flipper_length_mm",
"body_mass_g"
)
as_tibble(penguins)
})
predict <- reactive({
ldamodel <- readRDS("./model.rds")
predicted <- augment(ldamodel, datainput())
predicted
})
output$prediction <- renderTable({
predict() |>
select(-bill_length_mm,
-bill_depth_mm,
-flipper_length_mm,
-body_mass_g,
-.pred_class)
})
output$value <- renderTable({
predict() |>
select(.pred_class)
})
}
# Run the application
shinyApp(ui = ui, server = server)
runApp('Programs/R/Penguin Shiny.R')
library(tidyverse)
library(readxl)
PHILIPPINES <- read_excel("farmgate.xlsx", sheet = 1)
CAR <- read_excel("farmgate.xlsx", sheet = 3)
CAGAYAN_VALLEY <- read_excel("farmgate.xlsx", sheet = 4)
CENTRAL_LUZON <- read_excel("farmgate.xlsx", sheet = 5)
setwd("~/Programs/Second_Year/2nd SEM/ANALYTICS")
library(tidyverse)
library(readxl)
PHILIPPINES <- read_excel("farmgate.xlsx", sheet = 1)
ILOCOS_REGION <- read_excel("farmgate.xlsx", sheet = 2)
CAR <- read_excel("farmgate.xlsx", sheet = 3)
CAGAYAN_VALLEY <- read_excel("farmgate.xlsx", sheet = 4)
CENTRAL_LUZON <- read_excel("farmgate.xlsx", sheet = 5)
CALABARZON <- read_excel("farmgate.xlsx", sheet = 6)
MIMAROPA <- read_excel("farmgate.xlsx", sheet = 7)
BICOL_REGION <- read_excel("farmgate.xlsx", sheet = 8)
WESTERN_VISAYAS <- read_excel("farmgate.xlsx", sheet = 9)
CENTRAL_VISAYAS <- read_excel("farmgate.xlsx", sheet = 10)
EASTERN_VISAYAS <- read_excel("farmgate.xlsx", sheet = 11)
NORTHERN_MINDANAO <- read_excel("farmgate.xlsx", sheet = 12)
ZAMBOANGA_PENINSULA <- read_excel("farmgate.xlsx", sheet = 13)
DAVAO_REGION <- read_excel("farmgate.xlsx", sheet = 14)
SOCCKSARGEN <- read_excel("farmgate.xlsx", sheet = 15)
CARAGA <- read_excel("farmgate.xlsx", sheet = 16)
BARMM <- read_excel("farmgate.xlsx", sheet = 17)
SOUTHERN_TAGALOG <- read_excel("farmgate.xlsx", sheet = 18)
METRO_MANILA <- read_excel("farmgate.xlsx", sheet = 19)
pivot_and_combine_rice_prices <- function(data_frames_list, region_names) {
require(tidyr)
require(dplyr)
require(purrr)
# Check if the lengths of inputs match
if(length(data_frames_list) != length(region_names)) {
stop("The number of data frames must match the number of region names")
}
# Map through each data frame and its corresponding region name
combined_data <- map2_dfr(data_frames_list, region_names, function(df, region) {
df %>%
mutate(Region = region) %>%
pivot_longer(
cols = -c(Year, Region),
names_to = "Price_Type",
values_to = "Price"
)
})
return(combined_data)
}
region_data <- pivot_and_combine_rice_prices(
list(BARMM, BICOL_REGION, CAGAYAN_VALLEY, CALABARZON, CAR, CARAGA, CENTRAL_LUZON,
CENTRAL_VISAYAS, DAVAO_REGION, EASTERN_VISAYAS, ILOCOS_REGION, METRO_MANILA, MIMAROPA,
NORTHERN_MINDANAO, SOCCKSARGEN, SOUTHERN_TAGALOG, WESTERN_VISAYAS, ZOMBOANGA_PENINSULA),
c("BARMM","BICOL_REGION","CAGAYAN_VALLEY","CALABARZON","CAR","CARAGA","CENTRAL_LUZON",
"CENTRAL_VISAYAS","DAVAO_REGION", "EASTERN_VISAYAS", "ILOCOS_REGION","METRO_MANILA","MIMAROPA",
"NORTHERN_MINDANAO","SOCCKSARGEN", "SOUTHERN_TAGALOG", "WESTERN_VISAYAS", "ZAMBOANGA_PENINSULA")
)
region_data <- pivot_and_combine_rice_prices(
list(BARMM, BICOL_REGION, CAGAYAN_VALLEY, CALABARZON, CAR, CARAGA, CENTRAL_LUZON,
CENTRAL_VISAYAS, DAVAO_REGION, EASTERN_VISAYAS, ILOCOS_REGION, METRO_MANILA, MIMAROPA,
NORTHERN_MINDANAO, SOCCKSARGEN, SOUTHERN_TAGALOG, WESTERN_VISAYAS, ZAMBOANGA_PENINSULA),
c("BARMM","BICOL_REGION","CAGAYAN_VALLEY","CALABARZON","CAR","CARAGA","CENTRAL_LUZON",
"CENTRAL_VISAYAS","DAVAO_REGION", "EASTERN_VISAYAS", "ILOCOS_REGION","METRO_MANILA","MIMAROPA",
"NORTHERN_MINDANAO","SOCCKSARGEN", "SOUTHERN_TAGALOG", "WESTERN_VISAYAS", "ZAMBOANGA_PENINSULA")
)
sum(is.na(region_data))
sum(duplicated(region_data))
View(philippines_long)
View(region_data)
glimpse(region_data)
data %>%
group_by(Price_Type) %>%
summarize(missing = sum(is.na(Price)), total = n(), percent_missing = mean(is.na(Price)) * 100)
# Missing by Region
data %>%
group_by(Region) %>%
summarize(missing = sum(is.na(Price)), total = n(), percent_missing = mean(is.na(Price)) * 100)
region_data %>%
group_by(Price_Type) %>%
summarize(missing = sum(is.na(Price)), total = n(), percent_missing = mean(is.na(Price)) * 100)
# Missing by Region
region_data %>%
group_by(Region) %>%
summarize(missing = sum(is.na(Price)), total = n(), percent_missing = mean(is.na(Price)) * 100)
region_data %>%
group_by(Price_Type) %>%
summarize(missing = sum(is.na(Price)), total = n(), percent_missing = mean(is.na(Price)) * 100)
# Missing by Region
region_data %>%
group_by(Region) %>%
summarize(missing = sum(is.na(Price)), total = n(), percent_missing = mean(is.na(Price)) * 100)
